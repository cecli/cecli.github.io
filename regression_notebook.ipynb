{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Loading the data\n",
    "import csv\n",
    "\n",
    "# open the file in universal line ending mode \n",
    "#the file called 2015_tree_data_updated.csv is exactly the same download for the first assignment, jusr re-named.\n",
    "#This file is not included in the repo because is very big\n",
    "with open('2015_tree_data_updated.csv', 'r') as infile:\n",
    "    # read the file as a dictionary for each row ({header : value})\n",
    "    reader = csv.DictReader(infile)\n",
    "    data = {} #empty set\n",
    "    for row in reader:\n",
    "        for header, value in row.items():\n",
    "            try:\n",
    "                data[header].append(value)\n",
    "            except KeyError:\n",
    "                data[header] = [value]\n",
    "Diameter = data['Diameter']\n",
    "Health = data['Health']\n",
    "Spc_Latin = data['Spc_Latin']\n",
    "Spc_Common = data['Spc_Common']\n",
    "Sidewalk_Condition = data['Sidewalk_Condition']\n",
    "problems = data['problems']\n",
    "root_stone = data['root_stone']\n",
    "root_grate = data['root_grate']\n",
    "root_other = data['root_other']\n",
    "trunk_wire = data['trunk_wire']\n",
    "trnk_light = data['trnk_light']\n",
    "trnk_other = data['trnk_other']\n",
    "brch_light = data['brch_light']\n",
    "brch_shoe = data['brch_shoe']\n",
    "brch_other = data['brch_other']\n",
    "Address = data['Address']\n",
    "Zipcode = data['Zipcode']\n",
    "CB = data['CB']\n",
    "Borough = data['Borough']\n",
    "Latitude = data['Latitude']\n",
    "Longitude = data['Longitude']\n",
    "neigh = data['Neighbourhoods']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim is to compute the avg diameter, amount of trees, avg house price and then air pollution for each neighboorhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dic_neigh_count = {}\n",
    "for n in neigh: \n",
    "    dic_neigh_count[n] = 0\n",
    "\n",
    "n_dic = {}\n",
    "n_list = list(set(list(neigh)))\n",
    "for n in n_list:\n",
    "    n_dic[n] = []\n",
    "i = 0\n",
    "for n in neigh: \n",
    "    n_dic[n].append(i)\n",
    "    i += 1\n",
    "\n",
    "#avg diameter in each neighboorhood\n",
    "index = 0\n",
    "dic_n = {}\n",
    "dic_n_count = {}\n",
    "for n in list(set(list(neigh))):\n",
    "    dic_n[n] = 0\n",
    "    dic_n_count[n] = 0\n",
    "\n",
    "for d in Diameter:\n",
    "    #if int(CB[index])<400 and int(CB[index])>299: \n",
    "    dic_n[neigh[index]] += float(d)\n",
    "    dic_n_count[neigh[index]] += 1\n",
    "    index += 1\n",
    "for k in dic_n.keys(): \n",
    "    if dic_n_count[k] <> 0:\n",
    "        dic_n[k] = float(dic_n[k]/dic_n_count[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'AirPollution/Modified/NO2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b67c2cf081fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AirPollution/Modified/NO2.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;31m# read the file as a dictionary for each row ({header : value})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m#empty set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'AirPollution/Modified/NO2.csv'"
     ]
    }
   ],
   "source": [
    "with open('AirPollution/Modified/NO2.csv', 'r') as infile:\n",
    "    # read the file as a dictionary for each row ({header : value})\n",
    "    reader = csv.DictReader(infile)\n",
    "    data = {} #empty set\n",
    "    for row in reader:\n",
    "        for header, value in row.items():\n",
    "            try:\n",
    "                data[header].append(value)\n",
    "            except KeyError:\n",
    "                data[header] = [value]\n",
    "\n",
    "boro_airno2 = data['Borough']\n",
    "geo_id_airno2 = data['Geography']\n",
    "geo_airno2 = data['Geography_id']\n",
    "mean_no2_airno2 = data['Mean (ppb)']\n",
    "\n",
    "dic_no2 = {}\n",
    "i = 0\n",
    "for d in geo_airno2: \n",
    "    dic_no2[d] = mean_no2_airno2[i]\n",
    "    i += 1\n",
    "\n",
    "with open('AirPollution/Modified/O3.csv', 'r') as infile:\n",
    "    # read the file as a dictionary for each row ({header : value})\n",
    "    reader = csv.DictReader(infile)\n",
    "    data = {} #empty set\n",
    "    for row in reader:\n",
    "        for header, value in row.items():\n",
    "            try:\n",
    "                data[header].append(value)\n",
    "            except KeyError:\n",
    "                data[header] = [value]\n",
    "\n",
    "boro_airo3 = data['Borough']\n",
    "geo_id_airo3 = data['Geography']\n",
    "geo_airo3 = data['Geography_id']\n",
    "mean_air03 = data['Mean (ppb)']\n",
    "\n",
    "dic_o3 = {}\n",
    "i = 0\n",
    "for d in geo_airo3: \n",
    "    dic_o3[d] = mean_air03[i]\n",
    "    i += 1\n",
    "\n",
    "with open('AirPollution/Modified/PM25.csv', 'r') as infile:\n",
    "    # read the file as a dictionary for each row ({header : value})\n",
    "    reader = csv.DictReader(infile)\n",
    "    data = {} #empty set\n",
    "    for row in reader:\n",
    "        for header, value in row.items():\n",
    "            try:\n",
    "                data[header].append(value)\n",
    "            except KeyError:\n",
    "                data[header] = [value]\n",
    "\n",
    "boro_airpm25 = data['Borough']\n",
    "geo_id_airpm25 = data['Geography']\n",
    "geo_airpm25 = data['Geography_id']\n",
    "mean_airpm25 = data['Mean (mcg per cubic meter)']\n",
    "\n",
    "dic_pm25 = {}\n",
    "i = 0\n",
    "for d in geo_airpm25: \n",
    "    dic_pm25[d] = mean_airpm25[i]\n",
    "    i += 1\n",
    "\n",
    "\n",
    "\n",
    "with open('AirPollution/Modified/Black_Carbon.csv', 'r') as infile:\n",
    "    # read the file as a dictionary for each row ({header : value})\n",
    "    reader = csv.DictReader(infile)\n",
    "    data = {} #empty set\n",
    "    for row in reader:\n",
    "        for header, value in row.items():\n",
    "            try:\n",
    "                data[header].append(value)\n",
    "            except KeyError:\n",
    "                data[header] = [value]\n",
    "\n",
    "boro_airpmbc = data['Borough']\n",
    "geo_id_airbc = data['Geography']\n",
    "geo_airbc = data['Geography_id']\n",
    "mean_no2_airbc = data['Mean (absorbance units)']\n",
    "\n",
    "dic_bc = {}\n",
    "i = 0\n",
    "for d in geo_airbc: \n",
    "    dic_bc[d] = mean_no2_airbc[i]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dic_n_cb = {}\n",
    "#initiailize dictionary with list of neigh\n",
    "for n in list(set(list(neigh))): \n",
    "    dic_n_cb[n] = 'E'\n",
    "\n",
    "unique_n_list = list(set(list(neigh)))\n",
    "list_n_done = []\n",
    "len_unique_n_list = len(unique_n_list)\n",
    "\n",
    "i = 0 \n",
    "list_cb = []\n",
    "list_boro = []\n",
    "list_n = []\n",
    "\n",
    "i = 0\n",
    "for n in neigh: \n",
    "    if n not in list_n_done:\n",
    "        list_n.append(n)\n",
    "        list_n_done.append(n)\n",
    "        list_cb.append(CB[i])\n",
    "        list_boro.append(Borough[i])\n",
    "    i += 1\n",
    "    \n",
    "dic_n_no2 = {}\n",
    "dic_n_o3 = {}\n",
    "dic_n_pm25 = {}\n",
    "dic_n_bc = {}\n",
    "list_no2 = []\n",
    "list_o3 = []\n",
    "list_pm25 = []\n",
    "list_bc = []\n",
    "\n",
    "for x in list_cb: \n",
    "    list_no2.append(float(dic_no2[x]))\n",
    "    list_o3.append(float(dic_o3[x]))\n",
    "    list_pm25.append(float(dic_pm25[x]))\n",
    "    list_bc.append(float(dic_bc[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for n in list_n: \n",
    "    dic_n_no2[n] = list_no2[i]\n",
    "    dic_n_o3[n] = list_o3[i]\n",
    "    dic_n_pm25[n] = list_pm25[i]\n",
    "    dic_n_bc[n] = list_bc[i]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_tuple = []\n",
    "for n in list_n: \n",
    "    input_tuple.append([float(dic_n[n]), float(dic_n_count[n])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('AirPollutionLabeledPoint.csv', 'wb') as csvfile:\n",
    "    crimewriter = csv.writer(csvfile)\n",
    "    crimewriter.writerow(('Borough', 'CB', 'Neighbourhood'))\n",
    "    for xd, yd, zd in zip(list_boro, list_cb, list_n):\n",
    "        crimewriter.writerow( (xd, yd, zd ) )\n",
    "    csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#output air pollution lists\n",
    "with open('AirPollutionCSV/AirPollution_Mod.csv', 'wb') as csvfile:\n",
    "    crimewriter = csv.writer(csvfile)\n",
    "    crimewriter.writerow(('Borough', 'CB', 'Neighbourhood', 'NO2', 'O3', 'PM25', 'BC'))\n",
    "    for lb, lc, ln, xd, yd, zd, hd in zip(list_boro, list_cb, list_n, list_no2, list_o3, list_pm25, list_bc):\n",
    "        crimewriter.writerow( ( lb, lc, ln, xd, yd, zd, hd ) )\n",
    "    csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "input_tuple1 = []\n",
    "input_tuple2 = []\n",
    "for n in list_n: \n",
    "    input_tuple1.append(float(dic_n[n]))\n",
    "    input_tuple2.append(float(dic_n_count[n]))\n",
    "    \n",
    "#output air pollution lists\n",
    "with open('AirPollutionCSV/Diameter.csv', 'wb') as csvfile:\n",
    "    crimewriter = csv.writer(csvfile)\n",
    "    crimewriter.writerow(('Borough', 'CB', 'Neighbourhood', 'Diameter'))\n",
    "    for lb, lc, ln, xd in zip(list_boro, list_cb, list_n, input_tuple1):\n",
    "        crimewriter.writerow( ( lb, lc, ln, xd ) )\n",
    "    csvfile.close()\n",
    "\n",
    "#output air pollution lists\n",
    "with open('AirPollutionCSV/TreesAmount.csv', 'wb') as csvfile:\n",
    "    crimewriter = csv.writer(csvfile)\n",
    "    crimewriter.writerow(('Borough', 'CB', 'Neighbourhood', 'TreesAmount'))\n",
    "    for lb, lc, ln, xd in zip(list_boro, list_cb, list_n, input_tuple2):\n",
    "        crimewriter.writerow( ( lb, lc, ln, xd ) )\n",
    "    csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Define a function to multiply a scalar with a vector\n",
    "def scalar_multiply(c, v):\n",
    "    \"\"\"c is a number, v is a vector\"\"\"\n",
    "    return [c * v_i for v_i in v]\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "coeff_diam = []\n",
    "intercept_diam = []\n",
    "coeff_treesAmount = []\n",
    "intercept_treesAmount = []\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.set_xlabel('diameter')\n",
    "ax1.set_ylabel('no2')\n",
    "ax1.scatter(np.asarray(input_tuple1), np.asarray(list_no2))\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "self_lin = reg.fit(np.asarray(input_tuple1).reshape(-1,1), np.asarray(list_no2).reshape(-1,1)) #reshape arrays\n",
    "coeff_diam.append(reg.coef_)\n",
    "intercept_diam.append(reg.intercept_)\n",
    "print \"Beta=\", reg.coef_, \n",
    "print \"\"\n",
    "print \"Alpha=\", reg.intercept_\n",
    "plt.plot(input_tuple1, scalar_multiply(reg.coef_[0][0], input_tuple1) + reg.intercept_[0], color='red')\n",
    "plt.show()\n",
    "fig, ax2 = plt.subplots()\n",
    "ax2.set_xlabel('trees amount')\n",
    "ax2.set_ylabel('no2')\n",
    "ax2.scatter(np.asarray(input_tuple2), np.asarray(list_no2))\n",
    "reg = linear_model.LinearRegression()\n",
    "self_lin = reg.fit(np.asarray(input_tuple2).reshape(-1,1), np.asarray(list_no2).reshape(-1,1)) #reshape arrays\n",
    "coeff_treesAmount.append(reg.coef_)\n",
    "intercept_treesAmount.append(reg.intercept_)\n",
    "print \"Beta=\", reg.coef_, \n",
    "print \"\"\n",
    "print \"Alpha=\", reg.intercept_\n",
    "plt.plot(input_tuple2, scalar_multiply(reg.coef_[0][0], input_tuple2) + reg.intercept_[0], color='red')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel('diameter')\n",
    "ax.set_ylabel('o3')\n",
    "ax.scatter(np.asarray(input_tuple1), np.asarray(list_o3))\n",
    "reg = linear_model.LinearRegression()\n",
    "self_lin = reg.fit(np.asarray(input_tuple1).reshape(-1,1), np.asarray(list_o3).reshape(-1,1)) #reshape arrays\n",
    "coeff_diam.append(reg.coef_)\n",
    "intercept_diam.append(reg.intercept_)\n",
    "print \"Beta=\", reg.coef_, \n",
    "print \"\"\n",
    "print \"Alpha=\", reg.intercept_\n",
    "plt.plot(input_tuple1, scalar_multiply(reg.coef_[0][0], input_tuple1) + reg.intercept_[0], color='red')\n",
    "plt.show()\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel('trees amount')\n",
    "ax.set_ylabel('o3')\n",
    "ax.scatter(np.asarray(input_tuple2), np.asarray(list_o3))\n",
    "reg = linear_model.LinearRegression()\n",
    "self_lin = reg.fit(np.asarray(input_tuple2).reshape(-1,1), np.asarray(list_o3).reshape(-1,1)) #reshape arrays\n",
    "coeff_treesAmount.append(reg.coef_)\n",
    "intercept_treesAmount.append(reg.intercept_)\n",
    "print \"Beta=\", reg.coef_, \n",
    "print \"\"\n",
    "print \"Alpha=\", reg.intercept_\n",
    "plt.plot(input_tuple2, scalar_multiply(reg.coef_[0][0], input_tuple2) + reg.intercept_[0], color='red')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel('diameter')\n",
    "ax.set_ylabel('pm25')\n",
    "ax.scatter(np.asarray(input_tuple1), np.asarray(list_pm25))\n",
    "reg = linear_model.LinearRegression()\n",
    "self_lin = reg.fit(np.asarray(input_tuple1).reshape(-1,1), np.asarray(list_pm25).reshape(-1,1)) #reshape arrays\n",
    "coeff_diam.append(reg.coef_)\n",
    "intercept_diam.append(reg.intercept_)\n",
    "print \"Beta=\", reg.coef_, \n",
    "print \"\"\n",
    "print \"Alpha=\", reg.intercept_\n",
    "plt.plot(input_tuple1, scalar_multiply(reg.coef_[0][0], input_tuple1) + reg.intercept_[0], color='red')\n",
    "plt.show()\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel('trees amount')\n",
    "ax.set_ylabel('pm25')\n",
    "ax.scatter(np.asarray(input_tuple2), np.asarray(list_pm25))\n",
    "reg = linear_model.LinearRegression()\n",
    "self_lin = reg.fit(np.asarray(input_tuple2).reshape(-1,1), np.asarray(list_pm25).reshape(-1,1)) #reshape arrays\n",
    "coeff_treesAmount.append(reg.coef_)\n",
    "intercept_treesAmount.append(reg.intercept_)\n",
    "print \"Beta=\", reg.coef_, \n",
    "print \"\"\n",
    "print \"Alpha=\", reg.intercept_\n",
    "plt.plot(input_tuple2, scalar_multiply(reg.coef_[0][0], input_tuple2) + reg.intercept_[0], color='red')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel('diameter')\n",
    "ax.set_ylabel('black carbon')\n",
    "ax.scatter(np.asarray(input_tuple1), np.asarray(list_bc))\n",
    "reg = linear_model.LinearRegression()\n",
    "self_lin = reg.fit(np.asarray(input_tuple1).reshape(-1,1), np.asarray(list_bc).reshape(-1,1)) #reshape arrays\n",
    "coeff_diam.append(reg.coef_)\n",
    "intercept_diam.append(reg.intercept_)\n",
    "print \"Beta=\", reg.coef_, \n",
    "print \"\"\n",
    "print \"Alpha=\", reg.intercept_\n",
    "plt.plot(input_tuple1, scalar_multiply(reg.coef_[0][0], input_tuple1) + reg.intercept_[0], color='red')\n",
    "plt.show()\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel('trees amount')\n",
    "ax.set_ylabel('black carbon')\n",
    "ax.scatter(np.asarray(input_tuple2), np.asarray(list_bc))\n",
    "reg = linear_model.LinearRegression()\n",
    "self_lin = reg.fit(np.asarray(input_tuple2).reshape(-1,1), np.asarray(list_bc).reshape(-1,1)) #reshape arrays\n",
    "coeff_treesAmount.append(reg.coef_)\n",
    "intercept_treesAmount.append(reg.intercept_)\n",
    "print \"Beta=\", reg.coef_, \n",
    "print \"\"\n",
    "print \"Alpha=\", reg.intercept_\n",
    "plt.plot(input_tuple2, scalar_multiply(reg.coef_[0][0], input_tuple2) + reg.intercept_[0], color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('AirPollutionCSV/CoeffInterDiam.csv', 'wb') as csvfile:\n",
    "    crimewriter = csv.writer(csvfile)\n",
    "    crimewriter.writerow(('Coeff', 'Intercept'))\n",
    "    for xd, yd in zip(coeff_diam, intercept_diam):\n",
    "        crimewriter.writerow( ( float(xd), float(yd) ) )\n",
    "    csvfile.close()\n",
    "with open('AirPollutionCSV/CoeffInterTreesAmount.csv', 'wb') as csvfile:\n",
    "    crimewriter = csv.writer(csvfile)\n",
    "    crimewriter.writerow(('Coeff', 'Intercept'))\n",
    "    for xd, yd in zip(coeff_treesAmount, intercept_treesAmount):\n",
    "        crimewriter.writerow( ( float(xd), float(yd) ) )\n",
    "    csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Loading the data\n",
    "import csv\n",
    "\n",
    "# open the file in universal line ending mode \n",
    "#the file called 2015_tree_data_updated.csv is exactly the same download for the first assignment, jusr re-named.\n",
    "#This file is not included in the repo because is very big\n",
    "with open('2015_tree_data_brooklyn.csv', 'r') as infile:\n",
    "    # read the file as a dictionary for each row ({header : value})\n",
    "    reader = csv.DictReader(infile)\n",
    "    data = {} #empty set\n",
    "    for row in reader:\n",
    "        for header, value in row.items():\n",
    "            try:\n",
    "                data[header].append(value)\n",
    "            except KeyError:\n",
    "                data[header] = [value]\n",
    "Diameter = data['Diameter']\n",
    "Health = data['Health']\n",
    "Spc_Latin = data['Spc_Latin']\n",
    "Spc_Common = data['Spc_Common']\n",
    "Sidewalk_Condition = data['Sidewalk_Condition']\n",
    "problems = data['problems']\n",
    "root_stone = data['root_stone']\n",
    "root_grate = data['root_grate']\n",
    "root_other = data['root_other']\n",
    "trunk_wire = data['trunk_wire']\n",
    "trnk_light = data['trnk_light']\n",
    "trnk_other = data['trnk_other']\n",
    "brch_light = data['brch_light']\n",
    "brch_shoe = data['brch_shoe']\n",
    "brch_other = data['brch_other']\n",
    "Address = data['Address']\n",
    "Zipcode = data['Zipcode']\n",
    "CB = data['CB']\n",
    "Borough = data['Borough']\n",
    "Latitude = data['Latitude']\n",
    "Longitude = data['Longitude']\n",
    "neigh_brooklyn = data['Neighbourhoods']\n",
    "\n",
    "dic_neigh_brooklyn = {}\n",
    "unique_neigh_br = (list(set(list(neigh_brooklyn))))\n",
    "for n in unique_neigh_br:\n",
    "    dic_neigh_brooklyn[n] = 0\n",
    "for n in neigh_brooklyn:\n",
    "    dic_neigh_brooklyn[n] += 1\n",
    "\n",
    "#Loading the data\n",
    "import csv\n",
    "\n",
    "# open the file in universal line ending mode \n",
    "#the file called 2015_tree_data_updated.csv is exactly the same download for the first assignment, jusr re-named.\n",
    "#This file is not included in the repo because is very big\n",
    "with open('brooklyn_sales15.csv', 'r') as infile:\n",
    "    # read the file as a dictionary for each row ({header : value})\n",
    "    reader = csv.DictReader(infile)\n",
    "    data = {} #empty set\n",
    "    for row in reader:\n",
    "        for header, value in row.items():\n",
    "            try:\n",
    "                data[header].append(value)\n",
    "            except KeyError:\n",
    "                data[header] = [value]\n",
    "neigh_sales = data['Neighbourhoods']\n",
    "sale_price = data[\"SALE PRICE\"]\n",
    "\n",
    "unique_neigh = (list(set(list(neigh_sales))))\n",
    "dic_sales = {}\n",
    "dic_sales_count = {}\n",
    "for n in unique_neigh:\n",
    "    dic_sales[n] = 0\n",
    "    dic_sales_count[n] = 0.00\n",
    "    \n",
    "i = 0 \n",
    "for d in sale_price:\n",
    "    dic_sales[neigh_sales[i]] += float(d)\n",
    "    dic_sales_count[neigh_sales[i]] += 1.00\n",
    "    i += 1\n",
    "    \n",
    "for n in dic_sales.keys():\n",
    "    dic_sales[n] = float(dic_sales[n] / dic_sales_count[n])\n",
    "\n",
    "list_sales = []\n",
    "list_amount = []\n",
    "\n",
    "for n in unique_neigh: \n",
    "    list_sales.append(dic_sales[n])\n",
    "    list_amount.append(dic_neigh_brooklyn[n])\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel('trees amount')\n",
    "ax.set_ylabel('house prices')\n",
    "ax.scatter(np.asarray(list_amount), np.asarray(list_sales))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "alpha = 0.2\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(input_tuple\n",
    "                                                    , list_no2\n",
    "                                                    , test_size=0.25, random_state=42)\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "enet = ElasticNet(alpha=alpha, l1_ratio=0.7)\n",
    "\n",
    "y_pred_enet = enet.fit(X_train, y_train).predict(X_test)\n",
    "r2_score_enet = r2_score(y_test, y_pred_enet)\n",
    "print(\"r^2 elastic net on test data : %f\" % r2_score_enet)\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % np.mean((enet.predict(X_test) - y_test) ** 2))\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "alpha = 0.3\n",
    "lasso = Lasso(alpha=alpha)\n",
    "\n",
    "y_pred_lasso = lasso.fit(X_train, y_train).predict(X_test)\n",
    "r2_score_lasso = r2_score(y_test, y_pred_lasso)\n",
    "#print(lasso)\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % np.mean((lasso.predict(X_test) - y_test) ** 2))\n",
    "print(\"r^2 lasso on test data : %f\" % r2_score_lasso)\n",
    "\n",
    "reg = linear_model.LinearRegression()\n",
    "self_mul = reg.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % np.mean((reg.predict(X_test) - y_test) ** 2))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score (ols): %.2f' % reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regressor = DecisionTreeRegressor(random_state=0)\n",
    "regressor.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "n_folds = 5\n",
    "print np.mean(model_selection.cross_val_score(regressor, X_train, y_train,cv=n_folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#Create Decision tree classifier\n",
    "\n",
    "#Load relevant libraries\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn import model_selection\n",
    "\n",
    "#Split data set into a training and a test set\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(input_tuple\n",
    "                                                    , list_no2\n",
    "                                                    , test_size=0.33\n",
    "                                                    , random_state=42)\n",
    "\n",
    "\n",
    "#Classify Decision trees\n",
    "dt = tree.DecisionTreeClassifier(random_state = 42)\n",
    "\n",
    "#Fit the data and make predictions\n",
    "dt.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "#Calculate accuracy\n",
    "#score = dtnn.fit(X_train, y_train).score(X_test, y_test)\n",
    "n_folds = 5\n",
    "score = np.mean(model_selection.cross_val_score(dt.fit(X_train, y_train),X_train, y_train,cv=n_folds))\n",
    "print \"Decision tree accuracy for classifying top 10 species:\", score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for b in list(set(boro_airno2)):\n",
    "    for i in range(0,len(boro_airno2)):\n",
    "        if boro_airno2[i] == b:\n",
    "            print boro_airno2[i], '\\t\\t\\t', geo_id_airno2[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for g in geo_id_airno2: \n",
    "    if boro_airno2[i] == 'Queens':\n",
    "        print g\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list_neigh = list(set(list(neigh)))\n",
    "i = 0\n",
    "for n in list_neigh: \n",
    "    if Borough[i] == 'Bronx': \n",
    "        print n\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Bronx \t\t\tFordham - Bronx Pk\n",
    "Bronx \t\t\tKingsbridge - Riverdale\n",
    "Bronx \t\t\tNortheast Bronx\n",
    "Bronx \t\t\tPelham - Throgs Neck\n",
    "Bronx \t\t\tSouth Bronx\n",
    "Bronx \t\t\tCrotona -Tremont\n",
    "Bronx \t\t\tFordham - Bronx Pk\n",
    "Bronx \t\t\tHigh Bridge - Morrisania\n",
    "Bronx \t\t\tHunts Point - Mott Haven\n",
    "Bronx \t\t\tKingsbridge - Riverdale\n",
    "Bronx \t\t\tNortheast Bronx\n",
    "Bronx \t\t\tPelham - Throgs Neck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
