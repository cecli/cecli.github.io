{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1. Motivation\n",
    "## 1.1 Dataset\n",
    "The main dataset was the NYC Street Tree Data from 2015 and is the result of a community survery done mainly by volunteers, cataloging all trees in NYC. As secondary data sets we had the ones regarding Street Tree Data from 1995 and 2005. Moreover, we used the air pollution data in New York City, in order to understand the influence of trees on the air quality. We also started analyzing the \"311\" dataset, to explore some complaints regarding trees.\n",
    "The Street Tree dataset was chosen because it could give new insights and perspective to urban planning, discover their status (how healthy they are, if people are taking care of those etc.), and if they are influencing the life quality of the city. Moreover we could have discovered facts that most people would probably not be aware of beforehand.  \n",
    "\n",
    "\n",
    "## 1.2 Goal\n",
    "The goal was to enlighten users about trees in NYC. Are there certain types of trees more suitable for streets than others? Where are they located? Is it possible to know which kind of tree you might encounter based on the location, health of the tree, the diameter, or even the amount of problems of the tree? From this project it should be possible to learn something new about a topic you might never have considered learning something about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Basic stats\n",
    "## 2.1 Preprocessing the data\n",
    "### 2.1.1 Variable selection\n",
    "When taking a first glance at the dataset it was a bit overwhelming, as it's huge and there are a lot of rows which does not necessarily make sense at a first glance, as wel as a number of of variables not particularly interesting or necessary for what we wanted to do. Each variable was carefully examined and the variables deemed unnecessary were excluded. Among these was \"Tree_Id\", a unique ID for each tree, but this unique ID was unique for each of the three datasets (1995, 2005, 2015), meaning it was not possible to join the datasets by this ID, deeming it not relevant. Other excluded variables were address information, since there were multiple variables delivering address information on different levels - and it was not relevant to distinguish between all these. \n",
    "\n",
    "### 2.1.2 Observation selection\n",
    "It was decided to only focus on the top 20 tree species, since there were a lot of different species without a significant amount of observations, it would be difficult to describe them all properly. It would also be very difficult to do good predictions if the observations are sparse. \n",
    "\n",
    "There were a lot of trees without a species listed, and those were disregarded completely. The dead trees were also excluded from the dataset. \n",
    "\n",
    "It was considered to only focus on one of the five boroughs in NYC to get a more detailed view. This was not implemented since it was deemed more interesting to two differences between the boroughs as well. \n",
    "\n",
    "\n",
    "## 2.2 Stats for the preprocessed data\n",
    "The final dataset \"Street Tree Data 2015\" consists of 534,514 tree observations and 21 variables/features, totalling 74.5 MB.\n",
    "The selected features were: \n",
    "* Diameter (inches)\n",
    "* Health (three values: Good, fair, poor)\n",
    "* Spc_Latin, Spc_Common (latin and common name for the species) \n",
    "* Sidewalk_Condition (two values: Damage, NoDamage)\n",
    "* Problems (a string concatenated from the following types of problems)\n",
    " * root_stone, root_grate, root_other, trunk_wire, trnk_light, trnk_other, brch_light, brch_shoe, brch_other (two values: yes/no)\n",
    "* Address\n",
    "* Zipcode\n",
    "* CB (community board)\n",
    "* Borough\n",
    "* Latitude, Longitude\n",
    "\n",
    "Amount of trees in each borough:\n",
    "- Bronx: 63,035\n",
    "- Brooklyn: 138,760\n",
    "- Staten Island: 82,619\n",
    "- Manhattan: 54,115\n",
    "- Queens: 195,985\n",
    "\n",
    "In general, the top 20 species were the same for the 5 boroughs, but the order of this \"top 20\" list was different. There were more trees with general problems in Manhattan as well as more unhealthy trees. \n",
    "\n",
    "But let's start looking at the main dataset, the 2015 Street Tree Census (https://data.cityofnewyork.us/Environment/2015-Street-Tree-Census-Tree-Data/uvpi-gqnh).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File 2015_tree_data_updated.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cc740dc832ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtree_data15\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2015_tree_data_updated.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/thomasjn/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    560\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomasjn/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomasjn/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomasjn/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomasjn/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1211\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3427)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:6861)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: File 2015_tree_data_updated.csv does not exist"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tree_data15 = pd.read_csv('2015_tree_data_updated.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2.2.1 More observations in the data \n",
    "### <font color='red'> DANIELE: WRITE SOMETHING ABOUT WHAT YOU FOUND</font>\n",
    "\n",
    "## 2.3 Other datasets inspected\n",
    "Multiple secondary datasets were inspected, e.g. the 311 dataset and the airpollution dataset, as well as the Street Tree datasets from 2005 and 1995, respectively. In the 311 set, there were several complaints about trees in NYC. No significant correlations were found though. It was hoped that a connected between a certain type of complaint were correlated with different problems or the health of the tree, but unfortunately data does not always behave as hoped or suspected, and patterns cannot (and should not) be forced to appear. \n",
    "\n",
    "One could also be inclined to wonder if more \"green\" areas, meaning areas with a lot of trees, had higher house prices. Again, after investigation, this was found to be challenging, since there is not a lot of information about house prices available - at least not on a neighbourhood level. \n",
    "\n",
    "It was also considered if there was a correlation between the trees/features of the trees and the air pollution. This dataset was used for simple linear regression. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Theory\n",
    "\n",
    "## 3.1 Machine Learning tools\n",
    "When doing predictions it can be difficult to find the appropriate tools to use. Different tools have different qualities and it all depends on the data and the patterns in your data. In this project, different tools have been tried out, typically multiple tools for the same prediction to inspect the model performance of each tool. \n",
    "\n",
    "### 3.1.1 KNN\n",
    "KNN is a tool rather easy to grasp and implement. It was chosen for predicting the health of a tree based on GPS coordinates, as well as predicting species based on GPS coordinates. An argument for KNN being the most appropriate choice is that one could think that when planting trees, one would be inclined to plant the same trees together. One could also think that unhealthy trees are likely in the same area, presumable because of a decease in the area, a pollution problem, soil problems or something completely different. A drawback of the KNN method is that when dealing when an unbalanced dataset it will favour the most occuring observation. \n",
    "\n",
    "### 3.1.2 Decision trees\n",
    "Decision trees can often be a good choice because they are nice to visualize. A drawback is that they tend to overfit the training data. It was used for predicting health based on GPS coordinates, as well as species based on GPS coordinates in spite of its drawback. When predicting species different features were added to see if they contributed to the predictions, e.g. the diameter. The main reason was to compare with the other results. If the decision trees did not overfit and still performed well, then it would be nice to visualize. To accomodate the overfitting issue a random forest was also tried out.\n",
    "\n",
    "Decision trees were also used to predict diameter based on species and problems, as well as predicting diamater based on the amount of problems. Here, the diameter was binned in bins of different sizes (1-10, 10-15, 15-20, ..., 45-50, 50-60, 60-70, ..., 90-100, 100-150, 150-200, ...)\n",
    "\n",
    "### 3.1.3 SVM\n",
    "As a third tool, Support Vector Machines were tried out. SVMs can do linear classification by creating a \"maximum seperating hyperplane\" between data. It can also do non-linear classification using a so-called kernel-trick where inputs are mapped to high-dimensional feature space. This was used to predict health based on GPS coordinates. \n",
    "\n",
    "### 3.1.4 Apriori\n",
    "Apriori is an algorithm for frequent item search. It was used to inspect problems appearing together.\n",
    "<font color='red'> DANIELE: ADD MORE?</font>\n",
    "\n",
    "### 3.1.5 Linear regression\n",
    "Linear regression was used to inspect correlation between different features, and is not really a machine learning tool as much as a tool for investigating linear correlations. It was used to predict air pollution based on the amount of trees as well as diameter. \n",
    "\n",
    "## 3.2 Model selection\n",
    "When selecting appropriate models, first thing is to split the data into a training set and a test set. \n",
    "When predicting health (or species) based on GPS coordinates, a test set consisting of 15% of the total amount of observations was used. Hereafter the training set was \"split\" into a training set and a validation set, using a 5-fold cross-validation. The best model was chosen based on accuracy scored, but with computation time taken into account as well. For the KNN, different values of $k$ was tried, ranging from $K=2,...,10$. The limit was set to 10 because it was not expected that we would have a whole area of unhealthy trees, and that might just confuse the predictions. \n",
    "\n",
    "### <font color='red'> DANIELE: MISSING INFO - WHAT DID YOU Do?</font>\n",
    "\n",
    "## 3.3 Model performance\n",
    "For predicting species and health based on GPS coordinates, KNN was selected as the best model. SVM simply took a significant amount of time to run, making it difficult to fine tune and handle. Decision trees overfitted the training data and was not good at handling sparse data.\n",
    "\n",
    "For predicting species, the KNN classifier was able to predict $51.7$% accurately for $K=4$ on the test data, whereas the average (average over the 5 folds) performance on the validation set were $49.9$% (compared to $49$% for decision trees). This is considered rather good, taken into account that it is labelling $20$ different species, but it would also suggest that the same species is not always planted next to each other. They are actually not planted next to each other more often than expected before investigating the data. \n",
    "    In comparison, when only trying to predict the top 5 species instead of all 20 species, the average performance on the validation set were $70.4$% for $K=4$. This also confirms that the same species are not always planted next to each other, and shows, as expected, that the model performs better when addressing fewer species. \n",
    "\n",
    "For predicting health, the KNN classifier was able to predict $80.7$% accurately for $K=5$ on the test data, whereas the average (over the 5 folds) performance on the valdiation set were $80.4$% (compared to $74.8$% for decision trees). An accuracy of $80.7$% is rather good considering the sparsity of the \"fair\" and \"poor\" tree observations. The KNN did handle the sparsity trees better than the decision tree classifier. When it labeled a tree as \"fair\" it had around $43$% correct (on the validation set for $K=5$). A bit worse it went for the \"poor\" classifications, here it only predicted around $1/3$ correctly. It was, as we thought, much better at predicting the good trees. This makes sense since there were a lot more training data available. In comparison, the decision tree classifier had around $31$% correct for the \"fair\" trees, and $17$% for the \"poor\" trees. The amount of misclassifications on the \"poor\" and \"fair\" trees suggests that the condition of the trees do not really reflect on its neighbours and are most likely caused by other, individual things. \n",
    "\n",
    "### <font color='red'>DANIELE: WRITE SOMETHING ABOUT YOUR MODELS PERFORMANCE</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Visualizations\n",
    "\n",
    "## 4.1 Borough-basics\n",
    "The d3 pie charts show the basic distributions of the data: Amount of trees in each borough and the size of each borough. They were chosen so the user was able to get a clear view of the differences between the boroughs. As comparison, the other pie chart shows the size each borough. Here, it is obvious that the amount of trees in each borough roughly corresponds to the size of the borough, and the exact percentage can be viewed when hovering over each borough. \n",
    "\n",
    "These charts are important for the project since they introduce the user to the topic: What are the different boroughs, how are they different with regards to size and amount of trees? \n",
    "\n",
    "## 4.2 Tree distribution of top 5 species\n",
    "The d3 bar chart show the distribution of the 5 most common species in NYC for each borough, as well as NYC. This illustrates the borough-wise differences regarding the most common trees. E.g. the London Planetree is the most common tree in NYC. It is also the most common tree in Queens. Queens is the largest area in NYC both regarding trees and size, as shown in the pie charts. Therefore it might be that most of NYC's London Planetrees are located in Queens, but as it can be seen from the chart, most of them actually comes from Brooklyn. The chart also have the option of changing the years from 2015 to either 2005 or 1995, and hereby see the differences over time as well. \n",
    "\n",
    "This chart is important for the project since it enables the user to view the distribution of the most common trees in NYC on borough level for the three different years available: 1995, 2005, 2015. This helps us show the changes in street trees in NYC over time.\n",
    "\n",
    "## 4.3 Fun facts about the top 10 species\n",
    "This page enables the user to hover over pictures of leaves for the 10 most common species to see the species name, and then when clicking a leaf image, fun facts about these trees appear. \n",
    "\n",
    "This function is important for the project since it sets each of the trees in a context: What is it called? What is its ranking? How many trees are there of this species? What is special/interesting about the species? Why is it a good street tree compared to others? \n",
    "\n",
    "## 4.4 Health of the NYC street trees\n",
    "The d3 geoplot enables the user to view a prediction of the health of the NYC street trees, using KNN as a classifier. It is possible to hover for details, and to switch between visualizing the good, fair, and poor trees. \n",
    "### <font color='red'> THOMAS: MORE? add something about your plot</font>\n",
    "\n",
    "The geoplot is important for the project since it shows the location of the trees with different health. Because of the large amount of data points it would have created a too confusing picture to visualize all three health states at the same time. \n",
    "\n",
    "## 4.5 Scatterplot\n",
    "### <font color='red'> DANIELE: MISSING PLOT - write something about your plot</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Discussion\n",
    "When working with the project, two things became clear to us: \n",
    "1) Real life data is messy\n",
    "2) Data do not care what you think of them\n",
    "\n",
    "It is possible to have good intentions, and a lot of good ideas as to what to do when analyzing a dataset, but the data itself just have limitations that are not always possible to overcome. \n",
    "\n",
    "## 5.1 What went well?\n",
    "During the project, a lot of things did not go as expected. First of all, the pattern we expected to find in the data was just not there. The intention was to find correlation between the problems of the trees and the health, possible also correlation with the diameter. A lot of basic Pearson correlations was done on the data, but it appeared that there actually were no significant correlations. Then a lot of other datasets were inspected to see if they were correlated with some of the tree data features. Not a lot of great things appeared, so we tried keeping to the basics and that went quite well.\n",
    "\n",
    "We managed to create a lot of plots and visualizations of the data, showing the fundamentals counts. We also managed to apply different machine learning methods, though they only showed us what the preliminary analysis did: In general, there were not really large areas with problematic trees, and that could not really be related to the health. The health was sparse, influencing the predictions. \n",
    "\n",
    "## 5.2 Possible improvements\n",
    "If there was more data available to join with the street tree data, we might have been able to find a nice pattern/correlation, but in spite of our efforts to do so, we did not manage to find such data set. \n",
    "\n",
    "We could also have focused on one prediction goal instead of trying to find a lot of different patterns, that turned out to not be there. E.g. we could have focused on predicting species based but with some other tools, since KNN obviously was not the best choice. A suggestion would be to try do some binary classifications, locating e.g. London Planetrees using SVMs.\n",
    "\n",
    "## 5.3 What is still missing?\n",
    "In the end, what we actually missed was patterns in the data so we could have done some more advanced and great predictions. But patterns cannot be forced, so with that in mind, we could have used more visualizations for the predictions we did. We kept the website basic to try to create some beautiful visualizations of the basic stats instead of trying to visualize predictions in different ways. This choice was made based on the lack of good patterns. We did not really want to show a lot of predictions if they were not actually useful. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import data\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "tree_data = pd.read_csv('2015_tree_data_updated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Convert health categories to numbers. 1: Poor, 2: Fair, 3: Good. Higher = Better\n",
    "health = []\n",
    "for i in range(len(tree_data['Health'])):\n",
    "    if tree_data['Health'][i] == 'Good':\n",
    "        health.append(3)\n",
    "    elif tree_data['Health'][i] == 'Fair':\n",
    "        health.append(2)\n",
    "    elif tree_data['Health'][i] == 'Poor':\n",
    "        health.append(1)\n",
    "    else:\n",
    "        health.append(0)\n",
    "        #print \"err\", tree_data['Health'][i], i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queens           195985\n",
      "Brooklyn         138760\n",
      "Staten Island     82619\n",
      "Bronx             63035\n",
      "Manhattan         54115\n",
      "Name: Borough, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Count no. of trees in each borough:\n",
    "boros = tree_data['Borough'].unique()\n",
    "print tree_data['Borough'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data for histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queens data:\n",
      "[(31111, 'London planetree'), (22610, 'pin oak'), (20290, 'honeylocust'), (19407, 'Norway maple'), (16547, 'Callery pear'), (13497, 'cherry'), (11902, 'littleleaf linden'), (8987, 'Japanese zelkova'), (7389, 'green ash'), (6116, 'silver maple'), (5971, 'ginkgo'), (5386, 'Sophora'), (4935, 'red maple'), (4769, 'American linden'), (4146, 'silver linden'), (3035, 'purple-leaf plum'), (2992, 'maple'), (2697, 'northern red oak'), (2489, 'sweetgum'), (1709, 'American elm')]\n"
     ]
    }
   ],
   "source": [
    "#2015 data \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#NYC top 20 species\n",
    "unique, counts = np.unique(zip(tree_data['Spc_Common']), return_counts=True)\n",
    "sorted(zip(counts, unique), reverse = True)\n",
    "\n",
    "#Extract data for each borough\n",
    "tree_data_bronx = tree_data.loc[tree_data['Borough'] == 'Bronx']\n",
    "tree_data_brook = tree_data.loc[tree_data['Borough'] == 'Brooklyn']\n",
    "tree_data_stat = tree_data.loc[tree_data['Borough'] == 'Staten Island']\n",
    "tree_data_manh = tree_data.loc[tree_data['Borough'] == 'Manhattan']\n",
    "tree_data_queens = tree_data.loc[tree_data['Borough'] == 'Queens']\n",
    "\n",
    "#Bronx\n",
    "unique, counts = np.unique(zip(tree_data_bronx['Spc_Common']), return_counts=True)\n",
    "sorted(zip(counts, unique), reverse = True)\n",
    "\n",
    "#Brooklyn\n",
    "unique, counts = np.unique(zip(tree_data_brook['Spc_Common']), return_counts=True)\n",
    "sorted(zip(counts, unique), reverse = True)\n",
    "\n",
    "#Staten Island\n",
    "unique, counts = np.unique(zip(tree_data_stat['Spc_Common']), return_counts=True)\n",
    "sorted(zip(counts, unique), reverse = True)\n",
    "\n",
    "#Manhattan\n",
    "unique, counts = np.unique(zip(tree_data_manh['Spc_Common']), return_counts=True)\n",
    "sorted(zip(counts, unique), reverse = True)\n",
    "\n",
    "#Queens\n",
    "unique, counts = np.unique(zip(tree_data_queens['Spc_Common']), return_counts=True)\n",
    "print \"Queens data:\"\n",
    "print sorted(zip(counts, unique), reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilie\\.anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (6,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queens data:\n",
      "[(43756, 'MAPLE, NORWAY'), (32406, 'LONDON PLANETREE'), (19475, 'OAK, PIN'), (17428, 'PEAR, CALLERY'), (17136, 'HONEYLOCUST'), (11618, 'LINDEN, LITTLE LEAF'), (10179, 'MAPLE, SILVER'), (9422, 'ASH, GREEN'), (8012, 'UNKNOWN'), (7113, 'MAPLE, RED'), (5189, 'OAK, NORTHERN RED'), (5159, 'CHERRY, OTHER'), (4953, 'GINKGO'), (4537, 'ZELKOVA, JAPANESE'), (3064, 'LINDEN, AMERICAN'), (3010, 'MAPLE, NORWAY-CR KNG'), (2907, 'LINDEN, SILVER'), (2042, 'JAPANESE PAGODA TREE'), (1803, 'SWEETGUM'), (1449, 'ELM, AMERICAN')]\n"
     ]
    }
   ],
   "source": [
    "#2005 data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "tree_data = pd.read_csv('2005_tree_data_updated.csv')\n",
    "\n",
    "#NYC top 20 species\n",
    "unique, counts = np.unique(zip(tree_data['Spc_Common']), return_counts=True)\n",
    "sorted(zip(counts, unique), reverse = True)\n",
    "\n",
    "#Extract data for each borough\n",
    "tree_data_bronx = tree_data.loc[tree_data['Borough'] == 'Bronx']\n",
    "tree_data_brook = tree_data.loc[tree_data['Borough'] == 'Brooklyn']\n",
    "tree_data_stat = tree_data.loc[tree_data['Borough'] == 5]\n",
    "tree_data_manh = tree_data.loc[tree_data['Borough'] == 'Manhattan']\n",
    "tree_data_queens = tree_data.loc[tree_data['Borough'] == 'Queens']\n",
    "\n",
    "#Bronx\n",
    "unique, counts = np.unique(zip(tree_data_bronx['Spc_Common']), return_counts=True)\n",
    "sorted(zip(counts, unique), reverse = True)\n",
    "\n",
    "#Brooklyn\n",
    "unique, counts = np.unique(zip(tree_data_brook['Spc_Common']), return_counts=True)\n",
    "sorted(zip(counts, unique), reverse = True)\n",
    "\n",
    "#Staten Island\n",
    "unique, counts = np.unique(zip(tree_data_stat['Spc_Common']), return_counts=True)\n",
    "sorted(zip(counts, unique), reverse = True)\n",
    "\n",
    "#Manhattan\n",
    "unique, counts = np.unique(zip(tree_data_manh['Spc_Common']), return_counts=True)\n",
    "sorted(zip(counts, unique), reverse = True)\n",
    "\n",
    "#Queens\n",
    "unique, counts = np.unique(zip(tree_data_queens['Spc_Common']), return_counts=True)\n",
    "print \"Queens data:\"\n",
    "print sorted(zip(counts, unique), reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queens data:\n",
      "[(68738, 'MAPLE, NORWAY'), (32148, 'LONDON PLANETREE'), (17062, 'OAK, PIN'), (12117, 'MAPLE, SILVER'), (11684, 'LINDEN, LITTLE LEAF'), (10902, 'HONEYLOCUST'), (8991, 'PEAR, CALLERY'), (8716, 'ASH, GREEN'), (8294, 'PLANTING SITE'), (6840, 'MAPLE, SUGAR'), (5223, 'UNKNOWN LIVE TREES'), (4828, 'MAPLE, RED'), (4143, 'UNKNOWN DEAD TREES'), (4059, 'GINKGO'), (3334, 'MAPLE, SYCAMORE'), (3076, 'JAPANESE PAGODA TREE'), (2407, 'OAK, NORTHERN RED'), (2284, 'ZELKOVA, JAPANESE'), (1919, 'ELM, AMERICAN'), (1198, 'SWEETGUM')]\n"
     ]
    }
   ],
   "source": [
    "#1995 data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "tree_data = pd.read_csv('1995_tree_data_updated.csv')\n",
    "\n",
    "#NYC top 20 species\n",
    "unique, counts = np.unique(zip(tree_data['Spc_Common']), return_counts=True)\n",
    "sorted(zip(counts, unique), reverse = True)\n",
    "\n",
    "#Extract data for each borough\n",
    "tree_data_bronx = tree_data.loc[tree_data['Borough'] == 'Bronx']\n",
    "tree_data_brook = tree_data.loc[tree_data['Borough'] == 'Brooklyn']\n",
    "tree_data_stat = tree_data.loc[tree_data['Borough'] == 'Staten Island']\n",
    "tree_data_manh = tree_data.loc[tree_data['Borough'] == 'Manhattan']\n",
    "tree_data_queens = tree_data.loc[tree_data['Borough'] == 'Queens']\n",
    "\n",
    "#Bronx\n",
    "unique, counts = np.unique(zip(tree_data_bronx['Spc_Common']), return_counts=True)\n",
    "sorted(zip(counts, unique), reverse = True)\n",
    "\n",
    "#Brooklyn\n",
    "unique, counts = np.unique(zip(tree_data_brook['Spc_Common']), return_counts=True)\n",
    "sorted(zip(counts, unique), reverse = True)\n",
    "\n",
    "#Staten Island\n",
    "unique, counts = np.unique(zip(tree_data_stat['Spc_Common']), return_counts=True)\n",
    "sorted(zip(counts, unique), reverse = True)\n",
    "\n",
    "#Manhattan\n",
    "unique, counts = np.unique(zip(tree_data_manh['Spc_Common']), return_counts=True)\n",
    "sorted(zip(counts, unique), reverse = True)\n",
    "\n",
    "#Queens\n",
    "unique, counts = np.unique(zip(tree_data_queens['Spc_Common']), return_counts=True)\n",
    "print \"Queens data:\"\n",
    "print sorted(zip(counts, unique), reverse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting species based on location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN score for k = 2 : 0.486175963727\n",
      "KNN score for k = 3 : 0.495101214143\n",
      "KNN score for k = 4 : 0.499324634213\n",
      "KNN score for k = 5 : 0.503074537327\n",
      "KNN score for k = 6 : 0.50482382433\n",
      "KNN score for k = 7 : 0.506176855665\n",
      "KNN score for k = 8 : 0.507447748267\n",
      "KNN score for k = 9 : 0.508404531114\n",
      "KNN score for k = 10 : 0.508791118292\n"
     ]
    }
   ],
   "source": [
    "#KNN classifier\n",
    "\n",
    "#Load relevant libraries\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "from sklearn import neighbors, datasets, model_selection\n",
    "\n",
    "#Split data set into a training and a test set\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(zip(tree_data['Latitude'], tree_data['Longitude'] )\n",
    "                                                    , tree_data['Spc_Common']\n",
    "                                                    , test_size=0.15\n",
    "                                                    , random_state=42)\n",
    "\n",
    "\n",
    "accuracy = []\n",
    "#Classify KNN with K=2-10\n",
    "for k in range(2,11):\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=k, weights = \"distance\")\n",
    "\n",
    "    #Fit the data and make predictions\n",
    "    knn.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "    #Calculate accuracy from validation set\n",
    "    n_folds = 5\n",
    "    score = np.mean(model_selection.cross_val_score(knn.fit(X_train, y_train),X_train, y_train,cv=n_folds))\n",
    "    print \"KNN score for k =\", k, \":\", score\n",
    "    \n",
    "    #Save accuracy into a list\n",
    "    accuracy.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJ8AAAFNCAYAAACuQ87yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nh5wOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12d61f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot accuracy as a function of the number of K (2-10)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "ks = range(2, 11)\n",
    "plt.plot(ks, accuracy)\n",
    "plt.xticks(ks)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Prediction accuracy as a function of k\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.517340051206\n"
     ]
    }
   ],
   "source": [
    "#K=4 was chosen for simplicity compared to accuracy\n",
    "\n",
    "#Test score\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=4, weights = \"distance\")\n",
    "\n",
    "#Fit the data and make predictions\n",
    "knn.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "#Calculate accuracy\n",
    "score = knn.fit(X_train, y_train).score(X_test, y_test)\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(87014, 'London planetree'), (64264, 'honeylocust'), (58931, 'Callery pear'), (53185, 'pin oak'), (34189, 'Norway maple'), (29742, 'littleleaf linden'), (29279, 'cherry'), (29258, 'Japanese zelkova'), (21024, 'ginkgo'), (19338, 'Sophora'), (17246, 'red maple'), (16251, 'green ash'), (13530, 'American linden'), (12277, 'silver maple'), (10657, 'sweetgum'), (8400, 'northern red oak'), (7995, 'silver linden'), (7975, 'American elm'), (7080, 'maple'), (6879, 'purple-leaf plum')]\n",
      "297583\n",
      "KNN score for k = 2 : 0.704081936424\n",
      "KNN score for k = 3 : 0.702540110987\n",
      "KNN score for k = 4 : 0.704034511536\n",
      "KNN score for k = 5 : 0.702745680523\n",
      "KNN score for k = 6 : 0.701962891889\n",
      "KNN score for k = 7 : 0.701346174765\n",
      "KNN score for k = 8 : 0.700005955431\n",
      "KNN score for k = 9 : 0.698875265002\n",
      "KNN score for k = 10 : 0.69768924392\n"
     ]
    }
   ],
   "source": [
    "tree_data = pd.read_csv('2015_tree_data_updated.csv')\n",
    "\n",
    "unique, counts = np.unique(zip(tree_data['Spc_Common']), return_counts=True)\n",
    "print sorted(zip(counts, unique), reverse = True)\n",
    "#Try doing KNN for only the top 5 species\n",
    "top5_spec = ['London planetree','honeylocust', 'Callery pear','pin oak', 'Norway maple']\n",
    "tree_spec5 = []\n",
    "tree_lat5 = []\n",
    "tree_lon5 = []\n",
    "for i in range(len(tree_data)):\n",
    "    if tree_data['Spc_Common'][i] in top5_spec:\n",
    "        tree_spec5.append(tree_data['Spc_Common'][i])\n",
    "        tree_lat5.append(tree_data['Latitude'][i])\n",
    "        tree_lon5.append(tree_data['Longitude'][i])\n",
    "print len(tree_spec5)\n",
    "#print tree_spec5[:10]\n",
    "#print tree_lat5[:10]\n",
    "#print tree_lon5[:10]\n",
    "\n",
    "#KNN classifier\n",
    "#Load relevant libraries\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "from sklearn import neighbors, datasets, model_selection\n",
    "\n",
    "#Split data set into a training and a test set\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(zip(tree_lat5, tree_lon5)\n",
    "                                                    , tree_spec5\n",
    "                                                    , test_size=0.15\n",
    "                                                    , random_state=42)\n",
    "\n",
    "accuracy = []\n",
    "#Classify KNN with K=2-10\n",
    "for k in range(2,11):\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=k, weights = \"distance\")\n",
    "    \n",
    "    #Fit the data and make predictions\n",
    "    knn.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "    #Calculate accuracy\n",
    "    #score = knn.fit(X_train, y_train).score(X_test, y_test)\n",
    "    n_folds = 5\n",
    "    score = np.mean(model_selection.cross_val_score(knn.fit(X_train, y_train),X_train, y_train,cv=n_folds))\n",
    "    print \"KNN score for k =\", k, \":\", score\n",
    "    \n",
    "    #Save accuracy into a list\n",
    "    accuracy.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree accuracy: 0.490227832205\n"
     ]
    }
   ],
   "source": [
    "#Create Decision tree classifier\n",
    "\n",
    "#Load relevant libraries\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn import model_selection\n",
    "\n",
    "#Split data set into a training and a test set\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(zip(tree_data['Latitude'], tree_data['Longitude'])\n",
    "                                                    , tree_data['Spc_Common']\n",
    "                                                    , test_size=0.15\n",
    "                                                    , random_state=42)\n",
    "\n",
    "#Classify Decision trees\n",
    "dt = tree.DecisionTreeClassifier(random_state = 42)\n",
    "\n",
    "#Fit the data and make predictions\n",
    "dt.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "#Calculate accuracy\n",
    "#score = dtnn.fit(X_train, y_train).score(X_test, y_test)\n",
    "n_folds = 5\n",
    "score = np.mean(model_selection.cross_val_score(dt.fit(X_train, y_train),X_train, y_train,cv=n_folds))\n",
    "print \"Decision tree accuracy:\", score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify health based on location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilie\\.anaconda\\lib\\site-packages\\numpy\\lib\\arraysetops.py:200: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  flag = np.concatenate(([True], aux[1:] != aux[:-1]))\n",
      "C:\\Users\\Cecilie\\.anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:581: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN score for k = 2 : 0.768112149227\n",
      "KNN score for k = 3 : 0.789842752784\n",
      "KNN score for k = 4 : 0.798109764942\n",
      "KNN score for k = 5 : 0.804213182933\n",
      "KNN score for k = 6 : 0.80804514699\n",
      "KNN score for k = 7 : 0.810998909425\n",
      "KNN score for k = 8 : 0.813439834781\n",
      "KNN score for k = 9 : 0.815178637038\n",
      "KNN score for k = 10 : 0.816549869474\n"
     ]
    }
   ],
   "source": [
    "#Adjust KNN classifyer\n",
    "\n",
    "#Load relevant libraries\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "from sklearn import neighbors, datasets, model_selection\n",
    "\n",
    "#Split data set into a training and a test set\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(zip(tree_data['Latitude'], tree_data['Longitude'])\n",
    "                                                    , tree_data['Health']\n",
    "                                                    , test_size=0.15\n",
    "                                                    , random_state=42)\n",
    "\n",
    "accuracy = []\n",
    "#Classify KNN with K=2-10\n",
    "for k in range(2,11):\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=k, weights=\"distance\")\n",
    "\n",
    "    #Fit the data and make predictions\n",
    "    knn_pred = knn.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "    #Calculate accuracy\n",
    "    #score = knn.fit(X_train, y_train).score(X_test, y_test)\n",
    "    n_folds = 5\n",
    "    score = np.mean(model_selection.cross_val_score(knn.fit(X_train, y_train),X_train, y_train,cv=n_folds))\n",
    "    print \"KNN score for k =\", k, \":\", score\n",
    "    \n",
    "    #Save accuracy into a list\n",
    "    accuracy.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.806917109432\n"
     ]
    }
   ],
   "source": [
    "#Test accuracy\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5, weights=\"distance\")\n",
    "#Fit the data and make predictions\n",
    "knn_pred = knn.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "#Calculate accuracy\n",
    "score = knn.fit(X_train, y_train).score(X_test, y_test)\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree accuracy: 0.748111525321\n"
     ]
    }
   ],
   "source": [
    "#Create Decision tree classifier\n",
    "\n",
    "#Load relevant libraries\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn import model_selection\n",
    "\n",
    "\n",
    "#Split data set into a training and a test set\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(zip(tree_data['Latitude'], tree_data['Longitude'])\n",
    "                                                    , tree_data['Health']\n",
    "                                                    , test_size=0.15\n",
    "                                                    , random_state=42)\n",
    "\n",
    "#Classify Decision trees\n",
    "dt = tree.DecisionTreeClassifier(random_state = 42)\n",
    "\n",
    "#Fit the data and make predictions\n",
    "dt_pred = dt.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "#Calculate accuracy\n",
    "#score = dtnn.fit(X_train, y_train).score(X_test, y_test)\n",
    "n_folds = 5\n",
    "score = np.mean(model_selection.cross_val_score(dt.fit(X_train, y_train),X_train, y_train,cv=n_folds))\n",
    "print \"Decision tree accuracy:\", score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create SVM classifier\n",
    "\n",
    "#Load relevant libraries\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn import model_selection\n",
    "\n",
    "#Split data set into a training and a test set\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(zip(tree_data['Latitude'], tree_data['Longitude'])\n",
    "                                                    , tree_data['Health']\n",
    "                                                    , test_size=0.15\n",
    "                                                    , random_state=42)\n",
    "\n",
    "#Classify Decision trees\n",
    "svm = svm.SVC(random_state = 42)\n",
    "\n",
    "#Fit the data and make predictions\n",
    "svm.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "#Calculate accuracy\n",
    "#score = dtnn.fit(X_train, y_train).score(X_test, y_test)\n",
    "n_folds = 5\n",
    "score = np.mean(model_selection.cross_val_score(svm.fit(X_train, y_train),X_train, y_train,cv=n_folds))\n",
    "print \"SVM accuracy:\", score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
